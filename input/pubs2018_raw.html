
<!-- This document was automatically generated with bibtex2html 1.98
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     /usr/bin/bibtex2html -nodoc -dl -a -noabstract -nokeywords -o pubs2018_raw publications_bibtex/pubs2018.bib  -->


<dl>

<dt>
[<a name="2018proceedings2018">1</a>]
</dt>
<dd>
Proceedings of the 19th international society for music information retrieval
  conference, ismir 2018, paris, france, september 23-27, 2018.
 In E&nbsp;Gómez, X&nbsp;Hu, E&nbsp;Humphrey, and E&nbsp;Benetos, editors, <em>ISMIR</em>,
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#2018proceedings2018">bib</a>&nbsp;]

</dd>


<dt>
[<a name="alharbi2018applyingtweets">2</a>]
</dt>
<dd>
S&nbsp;Alharbi and M&nbsp;Purver.
 Applying distributional semantics to enhance classifying emotions in
  arabic tweets.
 pages 15--34, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#alharbi2018applyingtweets">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.5121/csit.2018.80602">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ali2018speakernetwork">3</a>]
</dt>
<dd>
H&nbsp;Ali, SN&nbsp;Tran, E&nbsp;Benetos, and AS&nbsp;d'Avila Garcez.
 Speaker recognition with hybrid features from a deep belief network.
 <em>Neural Computing and Applications</em>, 29(6):13--19, Mar 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#ali2018speakernetwork">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s00521-016-2501-7">DOI</a>&nbsp;| 
<a href="http://link.springer.com/article/10.1007/s00521-016-2501-7">http</a>&nbsp;]

</dd>


<dt>
[<a name="allik2018musiclynxgraphs">4</a>]
</dt>
<dd>
A&nbsp;Allik, F&nbsp;Thalmann, and M&nbsp;Sandler.
 Musiclynx: Exploring music through artist similarity graphs.
 In <em>The Web Conference 2018 - Companion of the World Wide Web
  Conference, WWW 2018</em>, pages 167--170, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#allik2018musiclynxgraphs">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3184558.3186970">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="armitage2018craftingstudy">5</a>]
</dt>
<dd>
JDK ARMITAGE and A&nbsp;MCPHERSON.
 Crafting digital musical instruments: An exploratory workshop study.
 Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#armitage2018craftingstudy">bib</a>&nbsp;]

</dd>


<dt>
[<a name="baker2018wearprogress">6</a>]
</dt>
<dd>
C&nbsp;Baker, H&nbsp;Ranaivoson, B&nbsp;Greinke, and N&nbsp;Bryan-Kinns.
 Wear: Wearable technologists engage with artists for responsible
  innovation: Processes and progress.
 <em>Virtual Creativity</em>, 8(1):91--105, Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#baker2018wearprogress">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1386/vcr.8.1.91_1">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="bear2018ananalysis">7</a>]
</dt>
<dd>
H&nbsp;BEAR and E&nbsp;BENETOS.
 An extensible cluster-graph taxonomy for open set sound scene
  analysis.
 In <em>http://dcase.community/workshop2018/</em>. Surrey, UK, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bear2018ananalysis">bib</a>&nbsp;| 
<a href="http://dcase.community/workshop2018/">http</a>&nbsp;]

</dd>


<dt>
[<a name="bechhofer2018prefacepreface">8</a>]
</dt>
<dd>
S&nbsp;Bechhofer, G&nbsp;Fazekas, and K&nbsp;Page.
 Preface.
 In <em>ACM International Conference Proceeding Series</em>, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bechhofer2018prefacepreface">bib</a>&nbsp;]

</dd>


<dt>
[<a name="benetos2018approachesanalysis">9</a>]
</dt>
<dd>
E&nbsp;BENETOS, D&nbsp;STOWELL, and M&nbsp;PLUMBLEY.
 Approaches to complex sound scene analysis.
 In T&nbsp;Virtanen, M&nbsp;PLUMBLEY, and D&nbsp;Ellis, editors, <em>Computational
  Analysis of Sound Scenes and Events</em>, number&nbsp;8 in Signals &amp; Communication,
  pages 215--242. Springer International Publishing, 1 edition, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#benetos2018approachesanalysis">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-63450-0">DOI</a>&nbsp;| 
<a href="http://www.springer.com/gb/book/9783319634494">http</a>&nbsp;]

</dd>


<dt>
[<a name="bengler2018collidoscopecollidoscope">10</a>]
</dt>
<dd>
B&nbsp;Bengler, F&nbsp;Martin, and N&nbsp;Bryan-Kinns.
 Collidoscope.
 <em>Interactions</em>, 25(2):12--13, Feb 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bengler2018collidoscopecollidoscope">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3183349">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="bin2018theperformance">11</a>]
</dt>
<dd>
SMA BIN.
 <em>The Show Must Go Wrong: Towards an understanding of audience
  perception of error in digital musical instrument performance</em>.
 PhD thesis, May 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bin2018theperformance">bib</a>&nbsp;]

</dd>


<dt>
[<a name="bin2018riskystrategy">12</a>]
</dt>
<dd>
SMA BIN, N&nbsp;BRYAN-KINNS, and AP&nbsp;MCPHERSON.
 Risky business: Disfluency as a design strategy.
 Blacksburg, VA, USA, Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bin2018riskystrategy">bib</a>&nbsp;]

</dd>


<dt>
[<a name="bromham2018themusic">13</a>]
</dt>
<dd>
G&nbsp;Bromham, D&nbsp;Moffat, M&nbsp;Barthet, and G&nbsp;Fazekas.
 The impact of compressor ballistics on the perceived style of music.
 In <em>145th Audio Engineering Society International Convention, AES
  2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bromham2018themusic">bib</a>&nbsp;]

</dd>


<dt>
[<a name="bryankinns2018caseengagement">14</a>]
</dt>
<dd>
N&nbsp;Bryan-Kinns.
 Case study of data mining mutual engagement.
 In <em>Electronic Workshops in Computing (eWiC)</em>, Jul 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bryankinns2018caseengagement">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.14236/ewic/hci2018.98">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="bryankinns2018exploringchina">15</a>]
</dt>
<dd>
N&nbsp;Bryan-Kinns, W&nbsp;Wang, and T&nbsp;Ji.
 Exploring interactivity and co-creation in rural china.
 <em>Interacting with Computers</em>, 30(4):273--292, Jul 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bryankinns2018exploringchina">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1093/iwc/iwy010">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="bryankinns2018thematicdesign">16</a>]
</dt>
<dd>
N&nbsp;Bryan-Kinns, W&nbsp;Wang, and Y&nbsp;Wu.
 Thematic analysis for sonic interaction design.
 In <em>Electronic Workshops in Computing (eWiC)</em>, Jul 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#bryankinns2018thematicdesign">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.14236/ewic/hci2018.214">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="buys2018realtimeapplications">17</a>]
</dt>
<dd>
K&nbsp;BUYS and A&nbsp;MCPHERSON.
 Real-time bowed string feature extraction for performance
  applications.
 In <em>https://zenodo.org/record/1422597</em>. Cyprus, Jul 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#buys2018realtimeapplications">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.5281/zenodo.1422597">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2018analysingsystem">18</a>]
</dt>
<dd>
B&nbsp;CHETTRI, S&nbsp;MISHRA, B&nbsp;STURM, and E&nbsp;BENETOS.
 Analysing the predictions of a cnn-based replay spoofing detection
  system.
 In <em>http://www.slt2018.org/</em>, pages 92--97. Athens, Greece, IEEE,
  Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#chettri2018analysingsystem">bib</a>&nbsp;]

</dd>


<dt>
[<a name="chettri2018analysingconditions">19</a>]
</dt>
<dd>
B&nbsp;CHETTRI, BLT STURM, and E&nbsp;BENETOS.
 Analysing replay spoofing countermeasure performance under varied
  conditions.
 Aalborg, Denmark, IEEE, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#chettri2018analysingconditions">bib</a>&nbsp;| 
<a href="http://mlsp2018.conwiz.dk/home.htm">http</a>&nbsp;]

</dd>


<dt>
[<a name="choi2018atagging">20</a>]
</dt>
<dd>
K&nbsp;Choi, G&nbsp;Fazekas, M&nbsp;Sandler, and K&nbsp;Cho.
 A comparison of audio signal preprocessing methods for deep neural
  networks on music tagging.
 In <em>Proc. of the 26th European Signal Processing Conference
  (EUSIPCO 2018), 3-7 Sept, Rome, Italy</em>, 2018.
 keywords: Signal Processing, Deep Learning, MIR, Auto-tagging
  date-added: 2018-05-06 23:32:25 +0000 date-modified: 2018-05-29 23:32:25
  +0000.
[&nbsp;<a href="pubs2018_raw_bib.html#choi2018atagging">bib</a>&nbsp;]

</dd>


<dt>
[<a name="choi2018thetagging">21</a>]
</dt>
<dd>
K&nbsp;Choi, G&nbsp;Fazekas, M&nbsp;Sandler, and K&nbsp;Cho.
 The effects of noisy labels on deep convolutional neural networks for
  music tagging.
 <em>IEEE Transactions on Emerging Topics in Computational
  Intelligence</em>, 2(2):139--149, Mar 2018.
 date-added: 2018-06-06 23:32:25 +0000 date-modified: 2018-05-06
  23:32:25 +0000 keywords: evaluation, music tagging, deep learning, CNN
  bdsk-url-1: https://arxiv.org/pdf/1706.02361.pdf bdsk-url-2:
  https://dx.doi.org/10.1109/TETCI.2017.2771298.
[&nbsp;<a href="pubs2018_raw_bib.html#choi2018thetagging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TETCI.2017.2771298">DOI</a>&nbsp;| 
<a href="http://semanticaudio.net/">http</a>&nbsp;]

</dd>


<dt>
[<a name="chourdakis2018fromtext">22</a>]
</dt>
<dd>
ET&nbsp;CHOURDAKIS and JOSHUAD REISS.
 From my pen to your ears: automatic production of radio plays from
  unstructured story text.
 Limassol, Cyprus, Jul 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#chourdakis2018fromtext">bib</a>&nbsp;| 
<a href="https://scholar.google.co.uk/citations?hl=en\&amp;user=Hf0rcRcAAAAJ">http</a>&nbsp;]

</dd>


<dt>
[<a name="dixon2018editorialretrieval">23</a>]
</dt>
<dd>
S&nbsp;Dixon, E&nbsp;Gómez, and A&nbsp;Volk.
 Editorial: Introducing the transactions of the international society
  for music information retrieval.
 <em>Transactions of the International Society for Music Information
  Retrieval</em>, 1(1):1--3, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#dixon2018editorialretrieval">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.5334/tismir.22">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="drooghayes2018automaticrepresentation">24</a>]
</dt>
<dd>
M&nbsp;Droog-Hayes, G&nbsp;Wiggins, and M&nbsp;Purver.
 Automatic detection of narrative structure for high-level story
  representation.
 In <em>Proceedings of AISB Annual Convention 2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#drooghayes2018automaticrepresentation">bib</a>&nbsp;]

</dd>


<dt>
[<a name="duffy2018refiningoverlap">25</a>]
</dt>
<dd>
S&nbsp;Duffy and PGT Healey.
 Refining musical performance through overlap.
 <em>Hacettepe Egitim Dergisi</em>, 33(Special Issue):316--333, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#duffy2018refiningoverlap">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.16986/HUJE.2018038809">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="duffy2018whatmusic">26</a>]
</dt>
<dd>
S&nbsp;Duffy and M&nbsp;Pearce.
 What makes rhythms hard to perform? an investigation using steve
  reich's clapping music.
 <em>PLoS One</em>, 13(10):e0205847--e0205847, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#duffy2018whatmusic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1371/journal.pone.0205847">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/30335798">http</a>&nbsp;]

</dd>


<dt>
[<a name="fanoyela2018doesseparation">27</a>]
</dt>
<dd>
D&nbsp;Fano&nbsp;Yela, D&nbsp;Stowell, and M&nbsp;Sandler.
 Does k matter? k-nn hubness analysis for kernel additive modelling
  vocal separation.
 In <em>Lecture Notes in Computer Science (including subseries
  Lecture Notes in Artificial Intelligence and Lecture Notes in
  Bioinformatics)</em>, volume 10891 LNCS, pages 280--289, Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#fanoyela2018doesseparation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-93764-9_27">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="flynn2018improvingfilters">28</a>]
</dt>
<dd>
J&nbsp;Flynn and JD&nbsp;Reiss.
 Improving the frequency response magnitude and phase of
  analogue-matched digital filters.
 In <em>144th Audio Engineering Society Convention 2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#flynn2018improvingfilters">bib</a>&nbsp;]

</dd>


<dt>
[<a name="freeman2018amaterial">29</a>]
</dt>
<dd>
J&nbsp;Freeman, G&nbsp;Wiggins, G&nbsp;Starks, and M&nbsp;Sandler.
 A concise taxonomy for describing data as an art material.
 In <em>Leonardo</em>, volume&nbsp;51, pages 75--79, Feb 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#freeman2018amaterial">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1162/LEON_a_01414">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="frieler2018twosolos">30</a>]
</dt>
<dd>
K&nbsp;Frieler, F&nbsp;Höger, M&nbsp;Pfleiderer, and S&nbsp;Dixon.
 Two web applications for exploring melodic patterns in jazz solos.
 In <em>Proceedings of the 19th International Society for Music
  Information Retrieval Conference, ISMIR 2018</em>, pages 777--783, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#frieler2018twosolos">bib</a>&nbsp;]

</dd>


<dt>
[<a name="galindoesparza2018augmentedpaper">31</a>]
</dt>
<dd>
RP&nbsp;Galindo&nbsp;Esparza, PGT Healey, L&nbsp;Weaver, and M&nbsp;Delbridge.
 Augmented embodiment: Developing interactive technology for stroke
  survivors short paper.
 In <em>ACM International Conference Proceeding Series</em>, Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#galindoesparza2018augmentedpaper">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3212721.3212845">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="goddard2018assessingcreativity">32</a>]
</dt>
<dd>
C&nbsp;GODDARD, M&nbsp;BARTHET, and G&nbsp;WIGGINS.
 Assessing musical similarity for computational music creativity.
 <em>Journal of the Audio Engineering Society</em>, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#goddard2018assessingcreativity">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2018.0012">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="goodman2018wearetextiles">33</a>]
</dt>
<dd>
L&nbsp;Goodman, N&nbsp;Bryan-Kinns, Y&nbsp;Wu, S&nbsp;Liu, and C&nbsp;Baker.
 Wear sustain network: Ethical and sustainable technology innovation
  in wearables and etextiles.
 In <em>2018 IEEE Games, Entertainment, Media Conference, GEM 2018</em>,
  pages 1--3, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#goodman2018wearetextiles">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/GEM.2018.8516276">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="healey2018editorsmiscommunication">34</a>]
</dt>
<dd>
PGT Healey, JP&nbsp;de&nbsp;Ruiter, and GJ&nbsp;Mills.
 Editors' introduction: Miscommunication.
 <em>Top Cogn Sci</em>, 10(2):264--278, May 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#healey2018editorsmiscommunication">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1111/tops.12340">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/29749040">http</a>&nbsp;]

</dd>


<dt>
[<a name="healey2018runningdialogue">35</a>]
</dt>
<dd>
PGT Healey, GJ&nbsp;Mills, A&nbsp;Eshghi, and C&nbsp;Howes.
 Running repairs: Coordinating meaning in dialogue.
 <em>Top Cogn Sci</em>, 10(2):367--388, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#healey2018runningdialogue">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1111/tops.12336">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/29687611">http</a>&nbsp;]

</dd>


<dt>
[<a name="healey2018selfrepetitionmonologue">36</a>]
</dt>
<dd>
PGT HEALEY and MRJ PURVER.
 Self-repetition in dialogue and monologue, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#healey2018selfrepetitionmonologue">bib</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/healey-purver18semdial.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="HEALEY2018">37</a>]
</dt>
<dd>
PGT HEALEY and MRJ PURVER.
 Self-repetition in dialogue and monologue, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#HEALEY2018">bib</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/healey-purver18semdial.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="heitlinger2018connectedcommunities">38</a>]
</dt>
<dd>
S&nbsp;Heitlinger, N&nbsp;Bryan-Kinns, and R&nbsp;Comber.
 Connected seeds and sensors: Co-designing internet of things for
  sustainable smart cities with urban food-growing communities.
 In <em>ACM International Conference Proceeding Series</em>, volume&nbsp;2,
  Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#heitlinger2018connectedcommunities">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3210604.3210620">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="hu2018identifyingnovices">39</a>]
</dt>
<dd>
Y&nbsp;Hu, X&nbsp;Du, N&nbsp;Bryan-Kinns, and Y&nbsp;Guo.
 Identifying divergent design thinking through the observable behavior
  of service design novices.
 <em>International Journal of Technology and Design Education</em>, Oct
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#hu2018identifyingnovices">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/s10798-018-9479-7">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="jack2018actionsoundmusicians">40</a>]
</dt>
<dd>
RH&nbsp;JACK, A&nbsp;MEHRABI, T&nbsp;Stockman, and A&nbsp;MCPHERSON.
 Action-sound latency and the perceived quality of digital musical
  instruments: Comparing professional percussionists and amateur musicians.
 <em>Music Perception</em>, Aug 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#jack2018actionsoundmusicians">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1525/mp.2018.36.1.109">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="jillings2018investigationresults">41</a>]
</dt>
<dd>
N&nbsp;Jillings, B&nbsp;De&nbsp;Man, R&nbsp;Stables, and JD&nbsp;Reiss.
 Investigation into the effects of subjective test interface choice on
  the validity of results.
 In <em>145th Audio Engineering Society International Convention, AES
  2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#jillings2018investigationresults">bib</a>&nbsp;]

</dd>


<dt>
[<a name="kudumakis2018enablingapplications">42</a>]
</dt>
<dd>
P&nbsp;KUDUMAKIS, J&nbsp;Corral&nbsp;García, I&nbsp;Barbancho, L&nbsp;J.&nbsp;Tardón, and M&nbsp;SANDLER.
 Enabling interactive and interoperable semantic music applications.
 In R&nbsp;Bader, editor, <em>Springer Handbook of Systematic Musicology</em>,
  number&nbsp;45 in Springer Handbooks, pages 911--921. Springer, Berlin,
  Heidelberg, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#kudumakis2018enablingapplications">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-662-55004-5_45">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="kudumakis2018dmrn132018">43</a>]
</dt>
<dd>
P&nbsp;KUDUMAKIS and S&nbsp;DIXON.
 Dmrn+13: Digital music research network workshop proceedings 2018.
 Centre for Digital Music, Queen Mary University of London, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#kudumakis2018dmrn132018">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.26494/DMRN.2018.53783">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="lavia2018nonparticipantpanning">44</a>]
</dt>
<dd>
L&nbsp;Lavia, HJ&nbsp;Witchel, F&nbsp;Aletta, J&nbsp;Steffens, A&nbsp;Fiebig, J&nbsp;Kang, C&nbsp;Howes, and PGT
  Healey.
 Non-participant observation methods for soundscape design and urban
  panning.
 In <em>Handbook of Research on Perception-Driven Approaches to Urban
  Assessment and Design</em>, pages 73--98. Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#lavia2018nonparticipantpanning">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.4018/978-1-5225-3637-6.ch004">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="li2018atests">45</a>]
</dt>
<dd>
S&nbsp;Li, S&nbsp;Dixon, and MD&nbsp;Plumbley.
 A demonstration of hierarchical structure usage in expressive timing
  analysis by model selection tests.
 In <em>Chinese Control Conference, CCC</em>, volume 2018-July, pages
  3190--3195, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#li2018atests">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.23919/ChiCC.2018.8483169">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="liang2018measurementtechniques">46</a>]
</dt>
<dd>
B&nbsp;Liang, G&nbsp;Fazekas, and M&nbsp;Sandler.
 Measurement, recognition and visualisation of piano pedalling
  gestures and techniques.
 <em>JAES Special Issue on Participatory Sound And Music Interaction
  Using Semantic Audio</em>, 2(47):xxxx--xxxx, Jun 2018.
 date-added: 2018-06-06 23:32:25 +0000 date-modified: 2018-05-06
  23:32:25 +0000 keywords: sensor system, piano pedalling, measurement, machine
  learning, gesture recognition, piano transcription.
[&nbsp;<a href="pubs2018_raw_bib.html#liang2018measurementtechniques">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2018.0035">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="Liang2018">47</a>]
</dt>
<dd>
B&nbsp;Liang, G&nbsp;Fazekas, and M&nbsp;Sandler.
 Measurement, recognition, and visualization of piano pedaling
  gestures and techniques.
 <em>AES: Journal of the Audio Engineering Society</em>, 66(6):448--456,
  Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#Liang2018">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2018.0035">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="liang2018pianomeasure">48</a>]
</dt>
<dd>
B&nbsp;Liang, G&nbsp;Fazekas, and M&nbsp;Sandler.
 Piano legato-pedal onset detection based on a sympathetic resonance
  measure.
 In <em>Proceedings of the 26th European Signal Processing Conference
  (EUSIPCO 2018)</em>, pages 2484--2488. Rome, IEEE, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#liang2018pianomeasure">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.23919/EUSIPCO.2018.8553341">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="marengo2018iart">49</a>]
</dt>
<dd>
L&nbsp;Marengo, G&nbsp;Fazekas, and A&nbsp;Tombros.
 I wonder... inquiry techniques as a method to gain insights into
  people’s encounters with visual art.
 In <em>Proc. International Conference on Museums and the Web 2018,
  April 18-21, Vancouver, Canada.</em>, 2018.
 date-added: 2018-05-01 00:11:04 +0000 date-modified: 2018-05-01
  00:16:25 +0000 keywords: visual art, information design, inquiry techniques,
  user requirements, online collections, interaction design bdsk-url-1:
  http://mw18.mwconf.org/paper/i-wonder-inquiry-techniques-as-a-method-to-gain-insights-into-peoples-encounters-with-visual-art.
[&nbsp;<a href="pubs2018_raw_bib.html#marengo2018iart">bib</a>&nbsp;| 
<a href="http://mw18.mwconf.org/paper/i-wonder-inquiry-techniques-as-a-method-to-gain-insights-into-peoples-encounters-with-visual-art">http</a>&nbsp;]

</dd>


<dt>
[<a name="martinezramirez2018endtoendnetworks">50</a>]
</dt>
<dd>
M&nbsp;Martinez&nbsp;Ramirez and J&nbsp;Reiss.
 End-to-end equalization with convolutional neural networks.
 Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#martinezramirez2018endtoendnetworks">bib</a>&nbsp;| 
<a href="http://www.m-marco.com/">http</a>&nbsp;]

</dd>


<dt>
[<a name="mcarthur2018perceptionvr">51</a>]
</dt>
<dd>
A&nbsp;McArthur, M&nbsp;Sandler, and R&nbsp;Stewart.
 Perception of mismatched auditory distance - cinematic vr.
 In <em>Proceedings of the AES International Conference</em>, volume
  2018-August, pages 24--33, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mcarthur2018perceptionvr">bib</a>&nbsp;]

</dd>


<dt>
[<a name="mccabe2018miscommunicationcommunication">52</a>]
</dt>
<dd>
R&nbsp;McCabe and PGT Healey.
 Miscommunication in doctor–patient communication.
 <em>Topics in Cognitive Science</em>, 10(2):409--424, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mccabe2018miscommunicationcommunication">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1111/tops.12337">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mehrabi2018similarityautoencoders">53</a>]
</dt>
<dd>
A&nbsp;Mehrabi, K&nbsp;Choi, S&nbsp;Dixon, and M&nbsp;Sandler.
 Similarity measures for vocal-based drum sample retrieval using deep
  convolutional auto-encoders.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2018-April, pages 356--360, Sep
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mehrabi2018similarityautoencoders">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2018.8461566">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="men2018lemoreality">54</a>]
</dt>
<dd>
L&nbsp;Men and N&nbsp;Bryan-Kinns.
 Lemo: Supporting collaborative music making in virtual reality.
 In <em>2018 IEEE 4th VR Workshop on Sonic Interactions for Virtual
  Environments, SIVE 2018</em>, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#men2018lemoreality">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/SIVE.2018.8577094">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mesaros2018detectionchallenge">55</a>]
</dt>
<dd>
A&nbsp;Mesaros, T&nbsp;Heittola, E&nbsp;Benetos, P&nbsp;Foster, M&nbsp;Lagrange, T&nbsp;Virtanen, and
  M&nbsp;Plumbley.
 Detection and classification of acoustic scenes and events: Outcome
  of the dcase 2016 challenge.
 <em>IEEE/ACM Transactions on Audio, Speech and Language Processing</em>,
  26:379--393, Feb 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mesaros2018detectionchallenge">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2017.2778423">DOI</a>&nbsp;| 
<a href="http://ieeexplore.ieee.org/document/8123864/">http</a>&nbsp;]

</dd>


<dt>
[<a name="milo2018graphicalsettings">56</a>]
</dt>
<dd>
A&nbsp;Milo, N&nbsp;Bryan-Kinns, and JD&nbsp;Reiss.
 Graphical research tools for acoustic design training: Capturing
  perception in architectural settings.
 In <em>Handbook of Research on Perception-Driven Approaches to Urban
  Assessment and Design</em>, pages 397--433. Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#milo2018graphicalsettings">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.4018/978-1-5225-3637-6.ch017">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mishra2018understandinginversion">57</a>]
</dt>
<dd>
S&nbsp;Mishra, BL&nbsp;Sturm, and S&nbsp;Dixon.
 Understanding a deep machine listening model through feature
  inversion.
 In <em>Proceedings of the 19th International Society for Music
  Information Retrieval Conference, ISMIR 2018</em>, pages 755--762, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mishra2018understandinginversion">bib</a>&nbsp;]

</dd>


<dt>
[<a name="mishra2018whatsystems">58</a>]
</dt>
<dd>
S&nbsp;Mishra, BL&nbsp;Sturm, and S&nbsp;Dixon.
 “what are you listening to?” explaining predictions of deep
  machine listening systems.
 In <em>European Signal Processing Conference</em>, volume
  2018-September, pages 2260--2264, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mishra2018whatsystems">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.23919/EUSIPCO.2018.8553178">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="moffat2018objectivesounds">59</a>]
</dt>
<dd>
D&nbsp;Moffat and J&nbsp;Reiss.
 Objective evaluations of synthesised environmental sounds.
 Aveiro, Portugal, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#moffat2018objectivesounds">bib</a>&nbsp;| 
<a href="http://dafx2018.web.ua.pt/#program">http</a>&nbsp;]

</dd>


<dt>
[<a name="moffat2018adaptivetracks">60</a>]
</dt>
<dd>
D&nbsp;Moffat and MB&nbsp;Sandler.
 Adaptive ballistics control of dynamic range compression for
  percussive tracks.
 In <em>145th Audio Engineering Society International Convention, AES
  2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#moffat2018adaptivetracks">bib</a>&nbsp;]

</dd>


<dt>
[<a name="moffat2018towardsrules">61</a>]
</dt>
<dd>
D&nbsp;Moffat, F&nbsp;Thalmann, and M&nbsp;Sandler.
 Towards a semantic web representation and application of audio mixing
  rules.
 Huddersfield, UK, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#moffat2018towardsrules">bib</a>&nbsp;]

</dd>


<dt>
[<a name="moffat2018perceptualeffects">62</a>]
</dt>
<dd>
DJ&nbsp;MOFFAT and JD&nbsp;REISS.
 Perceptual evaluation of synthesized sound effects.
 <em>ACM Transactions on Applied Perception (TAP)</em>, 15(2), Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#moffat2018perceptualeffects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3165287">DOI</a>&nbsp;| 
<a href="https://dl.acm.org/citation.cfm?id=3165287">http</a>&nbsp;]

</dd>


<dt>
[<a name="morfi2018deepdatasets">63</a>]
</dt>
<dd>
V&nbsp;Morfi and D&nbsp;Stowell.
 Deep learning for audio event detection and tagging on low-resource
  datasets.
 <em>Applied Sciences</em>, 8(8), Aug 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#morfi2018deepdatasets">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3390/app8081397">DOI</a>&nbsp;| 
<a href="http://arxiv.org/abs/1807.03697v2">http</a>&nbsp;]

</dd>


<dt>
[<a name="morreale2018effectperformance">64</a>]
</dt>
<dd>
F&nbsp;MORREALE, J&nbsp;ARMITAGE, and A&nbsp;MCPHERSON.
 Effect of instrument structure alterations on violin performance.
 <em>Frontiers in Psychology</em>, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#morreale2018effectperformance">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3389/fpsyg.2018.02436">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="mycroft2018amixing">65</a>]
</dt>
<dd>
J&nbsp;Mycroft, T&nbsp;Stockman, and JD&nbsp;Reiss.
 A prototype mixer to improve cross-modal attention during audio
  mixing.
 In <em>ACM International Conference Proceeding Series</em>, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#mycroft2018amixing">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3243274.3243290">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="nakamura2018towardsquantization">66</a>]
</dt>
<dd>
E&nbsp;Nakamura, E&nbsp;BENETOS, K&nbsp;Yoshii, and S&nbsp;DIXON.
 Towards complete polyphonic music transcription: Integrating
  multi-pitch detection and rhythm quantization.
 pages 101--105. Calgary, Canada, IEEE, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#nakamura2018towardsquantization">bib</a>&nbsp;| 
<a href="https://2018.ieeeicassp.org/">http</a>&nbsp;]

</dd>


<dt>
[<a name="nolasco2018torecognition">67</a>]
</dt>
<dd>
I&nbsp;Nolasco and E&nbsp;BENETOS.
 To bee or not to bee: Investigating machine learning approaches for
  beehive sound recognition.
 In <em>
  http://dcase.community/documents/workshop2018/proceedings/DCASE2018Workshop_Nolasco_131.pdf</em>.
  Surrey, UK, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#nolasco2018torecognition">bib</a>&nbsp;| 
<a href="http://dcase.community/workshop2018">http</a>&nbsp;]

</dd>


<dt>
[<a name="ohanlon2018improvedreassignment">68</a>]
</dt>
<dd>
K&nbsp;O'Hanlon and MB&nbsp;Sandler.
 Improved detection of semi-percussive onsets in audio using temporal
  reassignment.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2018-April, pages 611--615, Sep
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#ohanlon2018improvedreassignment">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2018.8461381">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="panteli2018acorpora">69</a>]
</dt>
<dd>
M&nbsp;PANTELI, E&nbsp;BENETOS, and S&nbsp;DIXON.
 A review of manual and computational approaches for the study of
  world music corpora.
 <em>Journal of New Music Research</em>, 47:176--189, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#panteli2018acorpora">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/09298215.2017.1418896">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="pardue2018improvingmanagement">70</a>]
</dt>
<dd>
LS&nbsp;Pardue, A&nbsp;McPherson, and D&nbsp;Overholt.
 Improving the instrumental learning experience through complexity
  management.
 In <em>Proceedings of the 15th Sound and Music Computing Conference:
  Sonic Crossings, SMC 2018</em>, pages 150--157, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pardue2018improvingmanagement">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pauwels2018recommendingcontent">71</a>]
</dt>
<dd>
J&nbsp;Pauwels, G&nbsp;Fazekas, and M&nbsp;Sandler.
 Recommending songs to music learners based on chord content.
 In <em>Proceedings of the 2018 Joint Workshop on Machine Learning
  for Music</em>. Stockholm, Sweden, Jul 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pauwels2018recommendingcontent">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pauwels2018pywebaudioplayertechnology">72</a>]
</dt>
<dd>
J&nbsp;Pauwels and M&nbsp;Sandler.
 pywebaudioplayer: Bridging the gap between audio processing code and
  attractive visualisations based on web technology.
 In <em>Proceedings of the 4th Web Audio Conference (WAC)</em>. Berlin,
  Germany, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pauwels2018pywebaudioplayertechnology">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pauwels2018exploringcollection">73</a>]
</dt>
<dd>
J&nbsp;Pauwels, A&nbsp;Xambó, G&nbsp;Roma, M&nbsp;Barthet, and G&nbsp;Fazekas.
 Exploring real-time visualisations to support chord learning with a
  large music collection.
 In <em>Proceedings of the 4th Web Audio Conference (WAC)</em>. Berlin,
  Germany, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pauwels2018exploringcollection">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pearce2018musicalperspectives">74</a>]
</dt>
<dd>
M&nbsp;Pearce and M&nbsp;Rohrmeier.
 Musical syntax ii: Empirical perspectives.
 In <em>Springer Handbooks</em>, pages 487--505. Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pearce2018musicalperspectives">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-662-55004-5_26">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="pearce2018statisticalenculturation">75</a>]
</dt>
<dd>
MT&nbsp;PEARCE.
 Statistical learning and probabilistic prediction in music cognition:
  Mechanisms of stylistic enculturation.
 <em>Annals of the New York Academy of Sciences</em>, May 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pearce2018statisticalenculturation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1111/nyas.13654">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="peng2018whypsychoacoustics">76</a>]
</dt>
<dd>
H&nbsp;Peng and JD&nbsp;Reiss.
 Why can you hear a difference between pouring hot and cold water? an
  investigation of temperature dependence in psychoacoustics.
 In <em>145th Audio Engineering Society International Convention, AES
  2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#peng2018whypsychoacoustics">bib</a>&nbsp;]

</dd>


<dt>
[<a name="pras2018apractices">77</a>]
</dt>
<dd>
A&nbsp;Pras, B&nbsp;De&nbsp;Man, and JD&nbsp;Reiss.
 A case study of cultural influences on mixing practices.
 In <em>144th Audio Engineering Society Convention 2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#pras2018apractices">bib</a>&nbsp;]

</dd>


<dt>
[<a name="purver2018computationalphenomena">78</a>]
</dt>
<dd>
MRJ PURVER, J&nbsp;HOUGH, and C&nbsp;HOWES.
 Computational models of miscommunication phenomena.
 <em>Topics in Cognitive Science</em>, Mar 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#purver2018computationalphenomena">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1111/tops.12324">DOI</a>&nbsp;| 
<a href="http://www.eecs.qmul.ac.uk/~mpurver/papers/purver-et-al18topics.pdf">.pdf</a>&nbsp;]

</dd>


<dt>
[<a name="quirogamartinez2018reducedcontexts">79</a>]
</dt>
<dd>
DR&nbsp;Quiroga-Martinez, NC&nbsp;Hansen, A&nbsp;Højlund, M&nbsp;Pearce, E&nbsp;Brattico, and P&nbsp;Vuust.
 Reduced prediction error responses in high- as compared to
  low-uncertainty musical contexts.
 <em>bioRxiv</em>, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#quirogamartinez2018reducedcontexts">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1101/422949">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="rohrmeier2018musicalperspectives">80</a>]
</dt>
<dd>
M&nbsp;Rohrmeier and M&nbsp;Pearce.
 Musical syntax i: Theoretical perspectives.
 In <em>Springer Handbooks</em>, pages 473--486. Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#rohrmeier2018musicalperspectives">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-662-55004-5_25">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="sears2018expectationseffects">81</a>]
</dt>
<dd>
DRW Sears, MT&nbsp;Pearce, J&nbsp;Spitzer, WE&nbsp;Caplin, and S&nbsp;McAdams.
 Expectations for tonal cadences: Sensory and cognitive priming
  effects.
 <em>Q J Exp Psychol (Hove)</em>, pages
  1747021818814472--1747021818814472, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#sears2018expectationseffects">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1177/1747021818814472">DOI</a>&nbsp;| 
<a href="https://www.ncbi.nlm.nih.gov/pubmed/30404574">http</a>&nbsp;]

</dd>


<dt>
[<a name="selfridge2018creatingmodels">82</a>]
</dt>
<dd>
R&nbsp;SELFRIDGE, D&nbsp;MOFFAT, E&nbsp;AVITAL, and J&nbsp;REISS.
 Creating real-time aeroacoustic sound effects using physically
  informed models.
 <em>Journal of the Audio Engineering Society</em>, 66(7/8):594--607, Aug
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#selfridge2018creatingmodels">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2018.0033">DOI</a>&nbsp;| 
<a href="http://www.aes.org/e-lib/browse.cfm?elib=19708">http</a>&nbsp;]

</dd>


<dt>
[<a name="selfridge2018physicallytone">83</a>]
</dt>
<dd>
R&nbsp;Selfridge, JD&nbsp;Reiss, and EJ&nbsp;Avital.
 Physically derived synthesis model of an edge tone.
 In <em>144th Audio Engineering Society Convention 2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#selfridge2018physicallytone">bib</a>&nbsp;]

</dd>


<dt>
[<a name="sheng2018featurecompressor">84</a>]
</dt>
<dd>
D&nbsp;Sheng and G&nbsp;Fazekas.
 Feature design using audio decomposition for intelligent control of
  the dynamic range compressor.
 In <em>Proc. of the IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP), April 15-20, Calgary, Canada.</em>, 2018.
 date-added: 2018-05-06 23:33:10 +0000 date-modified: 2018-05-07
  00:05:17 +0000 keywords: intelligent music production, ICASSP, intelligent
  audio effects local-url: sheng2018icassp.pdf.
[&nbsp;<a href="pubs2018_raw_bib.html#sheng2018featurecompressor">bib</a>&nbsp;| 
<a href="https://2018.ieeeicassp.org/Papers/ViewPapers.asp?PaperNum=3048">http</a>&nbsp;]

</dd>


<dt>
[<a name="sheng2018featureestimation">85</a>]
</dt>
<dd>
D&nbsp;Sheng and G&nbsp;Fazekas.
 Feature selection for dynamic range compressor parameter estimation.
 In <em>Proc. of the 144th Convention of the Audio Engineering
  Society, 23-26 May, Milan, Italy</em>, 2018.
 date-added: 2018-05-07 00:06:23 +0000 date-modified: 2018-05-07
  00:09:42 +0000 keywords: feature selection,. intelligent music production,
  AES, intelligent audio effects local-url: sheng2018aes.pdf.
[&nbsp;<a href="pubs2018_raw_bib.html#sheng2018featureestimation">bib</a>&nbsp;| 
<a href="http://www.aes.org/events/144/papers/?ID=5993">http</a>&nbsp;]

</dd>


<dt>
[<a name="shukla2018userevaluation">86</a>]
</dt>
<dd>
RC&nbsp;SHUKLA, RL&nbsp;STEWART, A&nbsp;Roginska, and MB&nbsp;SANDLER.
 User selection of optimal hrtf sets via holistic comparative
  evaluation.
 In <em>http://www.aes.org/e-lib/inst/browse.cfm?elib=19677</em>, pages
  1--10, New York, NY, USA, Aug 2018. Redmond, WA, USA, Audio Engineering
  Society.
[&nbsp;<a href="pubs2018_raw_bib.html#shukla2018userevaluation">bib</a>&nbsp;| 
<a href="http://www.aes.org/e-lib/">http</a>&nbsp;]

</dd>


<dt>
[<a name="skach2018smarttrousers">87</a>]
</dt>
<dd>
S&nbsp;Skach, R&nbsp;Stewart, and PGT Healey.
 Smart arse: Posture classification with textile sensors in trousers.
 In <em>ICMI 2018 - Proceedings of the 2018 International Conference
  on Multimodal Interaction</em>, pages 116--124, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#skach2018smarttrousers">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3242969.3242977">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="skach2018embodiedarts">88</a>]
</dt>
<dd>
S&nbsp;SKACH, A&nbsp;XAMBO, L&nbsp;TURCHET, A&nbsp;Stolfi, RL&nbsp;STEWART, and MHE BARTHET.
 Embodied interactions with e-textiles and the internet of sounds for
  performing arts.
 Stockholm, Sweden, Mar 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#skach2018embodiedarts">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3173225.3173272">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2018evaluatingseeking">89</a>]
</dt>
<dd>
AG&nbsp;STOCKMAN and D&nbsp;AL-THANI.
 Evaluating an interface for cross-modal information seeking.
 <em>Interacting With Computers</em>, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stockman2018evaluatingseeking">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1093/iwc/iwy017">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2018iworkspace">90</a>]
</dt>
<dd>
AG&nbsp;STOCKMAN and O&nbsp;METATLA.
 “i hear you”: Understanding awareness information exchange in an
  audio-only workspace.
 Montreal, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stockman2018iworkspace">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3173574.3174120">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stockman2018perceptioncues">91</a>]
</dt>
<dd>
T&nbsp;STOCKMAN and S&nbsp;Wilkie.
 Perception of objects that move in depth, using ecologically valid
  audio cues.
 <em>Applied Acoustics</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stockman2018perceptioncues">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.apacoust.2017.12.032">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stolfi2018audioperformances">92</a>]
</dt>
<dd>
A&nbsp;Stolfi, J&nbsp;Sokolovskis, F&nbsp;Gorodscy, F&nbsp;Iazzetta, and M&nbsp;Barthet.
 Audio semantics: Online chat communication in open band participatory
  music performances.
 <em>AES: Journal of the Audio Engineering Society</em>, 66(11):910--921,
  Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stolfi2018audioperformances">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2018.0048">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stoller2018detectionrearrangement">93</a>]
</dt>
<dd>
D&nbsp;Stoller, V&nbsp;Akkermans, and S&nbsp;Dixon.
 Detection of cut-points for automatic music rearrangement.
 In <em>IEEE International Workshop on Machine Learning for Signal
  Processing, MLSP</em>, volume 2018-September, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stoller2018detectionrearrangement">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/MLSP.2018.8516706">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stoller2018adversarialextraction">94</a>]
</dt>
<dd>
D&nbsp;Stoller, S&nbsp;Ewert, and S&nbsp;Dixon.
 Adversarial semi-supervised audio source separation applied to
  singing voice extraction.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2018-April, pages 2391--2395,
  Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stoller2018adversarialextraction">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2018.8461722">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="stoller2018jointlyapproach">95</a>]
</dt>
<dd>
D&nbsp;STOLLER, S&nbsp;Ewert, and S&nbsp;DIXON.
 Jointly detecting and separating singing voice: a multi-task
  approach.
 Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stoller2018jointlyapproach">bib</a>&nbsp;]

</dd>


<dt>
[<a name="stowell2018automaticchallenge">96</a>]
</dt>
<dd>
D&nbsp;Stowell, MD&nbsp;Wood, H&nbsp;Pamuła, Y&nbsp;Stylianou, and H&nbsp;Glotin.
 Automatic acoustic detection of birds through deep learning: The
  first bird audio detection challenge.
 <em>Methods in Ecology and Evolution</em>, Nov 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#stowell2018automaticchallenge">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1111/2041-210X.13103">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="thalmann2018culturaldata">97</a>]
</dt>
<dd>
F&nbsp;Thalmann, T&nbsp;Wilmering, and MB&nbsp;Sandler.
 Cultural heritage documentation and exploration of live music events
  with linked data.
 In <em>ACM International Conference Proceeding Series</em>, pages 1--5,
  Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#thalmann2018culturaldata">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3243907.3243910">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="thalmann2018atrees">98</a>]
</dt>
<dd>
FLORIAN THALMANN, L&nbsp;THOMPSON, and M&nbsp;SANDLER.
 A user-adaptive automated dj web app with object-based audio and
  crowd-sourced decision trees.
 Berlin, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#thalmann2018atrees">bib</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2018codesigncommunication">99</a>]
</dt>
<dd>
L&nbsp;TURCHET and M&nbsp;BARTHET.
 Co-design of musical haptic wearables for electronic music
  performer's communication.
 <em>IEEE Transactions on Human-Machine Systems</em>, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#turchet2018codesigncommunication">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/THMS.2018.2885408">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2018jammingaccompaniment">100</a>]
</dt>
<dd>
L&nbsp;Turchet and M&nbsp;Barthet.
 Jamming with a smart mandolin and freesound-based accompaniment.
 In <em>Conference of Open Innovation Association, FRUCT</em>, volume
  2018-November, pages 375--381, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#turchet2018jammingaccompaniment">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.23919/FRUCT.2018.8588110">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2018internetchallenges">101</a>]
</dt>
<dd>
L&nbsp;Turchet, C&nbsp;Fischione, G&nbsp;Essl, D&nbsp;Keller, and M&nbsp;Barthet.
 Internet of musical things: Vision and challenges.
 <em>IEEE Access</em>, 6:61994--62017, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#turchet2018internetchallenges">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ACCESS.2018.2872625">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2018codesigncajn">102</a>]
</dt>
<dd>
L&nbsp;Turchet, A&nbsp;McPherson, and M&nbsp;Barthet.
 Co-design of a smart cajón.
 <em>AES: Journal of the Audio Engineering Society</em>, 66(4):220--230,
  Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#turchet2018codesigncajn">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.17743/jaes.2018.0007">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2018realtimecajn">103</a>]
</dt>
<dd>
L&nbsp;Turchet, A&nbsp;McPherson, and M&nbsp;Barthet.
 Real-time hit classification in a smart cajón.
 <em>Frontiers in ICT</em>, 5, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#turchet2018realtimecajn">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3389/fict.2018.00016">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="turchet2018towardsthings">104</a>]
</dt>
<dd>
L&nbsp;Turchet, F&nbsp;Viola, G&nbsp;Fazekas, and M&nbsp;Barthet.
 Towards a semantic architecture for the internet of musical things.
 In <em>Conference of Open Innovation Association, FRUCT</em>, volume
  2018-November, pages 382--390, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#turchet2018towardsthings">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.23919/FRUCT.2018.8587917">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="valeromas2018atranscription">105</a>]
</dt>
<dd>
JJ&nbsp;Valero-Mas, E&nbsp;BENETOS, and JM&nbsp;Iñesta.
 A supervised classification approach for note tracking in polyphonic
  piano transcription.
 <em>Journal of New Music Research</em>, 47(3):249--263, Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#valeromas2018atranscription">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1080/09298215.2018.1451546">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="viola2018playsoundspacerecommendations">106</a>]
</dt>
<dd>
F&nbsp;Viola, A&nbsp;Stolfi, A&nbsp;Milo, M&nbsp;Ceriani, M&nbsp;Barthet, and G&nbsp;Fazekas.
 Playsound.space: Enhancing a live music performance tool with
  semantic recommendations.
 In <em>ACM International Conference Proceeding Series</em>, pages
  46--53, Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#viola2018playsoundspacerecommendations">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3243907.3243908">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="viola2018cthings">107</a>]
</dt>
<dd>
F&nbsp;Viola, L&nbsp;Turchet, F&nbsp;Antoniazzi, and G&nbsp;Fazekas.
 C minor: A semantic publish/subscribe broker for the internet of
  musical things.
 In <em>Conference of Open Innovation Association, FRUCT</em>, volume
  2018-November, pages 405--415, Dec 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#viola2018cthings">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.23919/FRUCT.2018.8588087">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wang2018towardsflute">108</a>]
</dt>
<dd>
C&nbsp;WANG, E&nbsp;BENETOS, X&nbsp;MENG, and E&nbsp;CHEW.
 Towards hmm-based glissando detection for recordings of chinese
  bamboo flute.
 In <em>http://ismir2018.ircam.fr/pages/events-lbd.html</em>. Paris,
  France, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#wang2018towardsflute">bib</a>&nbsp;]

</dd>


<dt>
[<a name="weaver2018analysisconditions">109</a>]
</dt>
<dd>
J&nbsp;Weaver, M&nbsp;Barthet, and E&nbsp;Chew.
 Analysis of piano duo tempo changes in varying convolution
  reverberation conditions.
 In <em>145th Audio Engineering Society International Convention, AES
  2018</em>, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#weaver2018analysisconditions">bib</a>&nbsp;]

</dd>


<dt>
[<a name="wilkinson2018amodelling">110</a>]
</dt>
<dd>
WJ&nbsp;Wilkinson, JD&nbsp;Reiss, and D&nbsp;Stowell.
 A generative model for natural sounds based on latent force
  modelling.
 In <em>Lecture Notes in Computer Science (including subseries
  Lecture Notes in Artificial Intelligence and Lecture Notes in
  Bioinformatics)</em>, volume 10891 LNCS, pages 259--269, Jun 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#wilkinson2018amodelling">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-93764-9_25">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="wilmering2018explorationweb">111</a>]
</dt>
<dd>
T&nbsp;Wilmering, F&nbsp;Thalmann, and MB&nbsp;Sandler.
 Exploration of grateful dead concerts and memorabilia on the semantic
  web.
 In <em>CEUR Workshop Proceedings</em>, volume 2180. Monterey, CA, Oct
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#wilmering2018explorationweb">bib</a>&nbsp;]

</dd>


<dt>
[<a name="wu2018musickingengagement">112</a>]
</dt>
<dd>
Y&nbsp;Wu and N&nbsp;Bryan-Kinns.
 Musicking with an interactive musical system: The effects of task
  motivation and user interface mode on non-musicians’ creative engagement.
 <em>International Journal of Human Computer Studies</em>, 122:61--77,
  Aug 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#wu2018musickingengagement">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.ijhcs.2018.07.009">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="xambo2018livedatabases">113</a>]
</dt>
<dd>
A&nbsp;Xambo, G&nbsp;Roma, A&nbsp;Lerch, M&nbsp;Barthet, and G&nbsp;Fazekas.
 Live repurposing of sounds: Mir explorations with personal and
  crowd-sourced databases.
 In <em>Proc. of the New Interfaces for Musical Expression (NIME),
  3-6 June, Blacksburg, VA, USA.</em>, 2018.
 date-added: 2018-05-07 00:22:07 +0000 date-modified: 2018-05-07
  00:28:09 +0000 keywords: live coding, MIR, sound samples, Creative Commons.
[&nbsp;<a href="pubs2018_raw_bib.html#xambo2018livedatabases">bib</a>&nbsp;]

</dd>


<dt>
[<a name="xamb2018jamperspective">114</a>]
</dt>
<dd>
A&nbsp;Xambó, J&nbsp;Pauwels, G&nbsp;Roma, M&nbsp;Barthet, and G&nbsp;Fazekas.
 Jam with jamendo: Querying a large music collection by chords from a
  learner's perspective.
 In <em>ACM International Conference Proceeding Series</em>, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#xamb2018jamperspective">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3243274.3243291">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2018amapsannotations">115</a>]
</dt>
<dd>
A&nbsp;YCART and E&nbsp;BENETOS.
 A-maps: Augmented maps dataset with rhythm and key annotations.
 Paris, Sep 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#ycart2018amapsannotations">bib</a>&nbsp;]

</dd>


<dt>
[<a name="ycart2018polyphonicnetworks">116</a>]
</dt>
<dd>
A&nbsp;YCART and E&nbsp;BENETOS.
 Polyphonic music sequence transduction with meter-constrained lstm
  networks.
 pages 386--390. Calgary, Canada, IEEE, Apr 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#ycart2018polyphonicnetworks">bib</a>&nbsp;]

</dd>


<dt>
[<a name="yela2018shiftinvariantseparation">117</a>]
</dt>
<dd>
DF&nbsp;Yela, S&nbsp;Ewert, K&nbsp;O'Hanlon, and MB&nbsp;Sandler.
 Shift-invariant kernel additive modelling for audio source
  separation.
 In <em>ICASSP, IEEE International Conference on Acoustics, Speech
  and Signal Processing - Proceedings</em>, volume 2018-April, pages 616--620, Sep
  2018.
[&nbsp;<a href="pubs2018_raw_bib.html#yela2018shiftinvariantseparation">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2018.8461801">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="zappi2018hackableinteraction">118</a>]
</dt>
<dd>
V&nbsp;ZAPPI and A&nbsp;MCPHERSON.
 Hackable instruments: Supporting appropriation and modification in
  digital musical interaction.
 <em>Frontiers in ICT</em>, 5(26), Oct 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#zappi2018hackableinteraction">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.3389/fict.2018.00026">DOI</a>&nbsp;]

</dd>


<dt>
[<a name="zhang2018humandog">119</a>]
</dt>
<dd>
L&nbsp;Zhang and PGT Healey.
 Human, chameleon or nodding dog?
 pages 428--436, Jan 2018.
[&nbsp;<a href="pubs2018_raw_bib.html#zhang2018humandog">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/3242969.3242998">DOI</a>&nbsp;]

</dd>
</dl><hr><p><em>This file was generated by
<a href="http://www.lri.fr/~filliatr/bibtex2html/">bibtex2html</a> 1.98.</em></p>
